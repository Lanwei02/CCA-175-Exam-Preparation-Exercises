// spark-shell --help
// hadoop fs -ls /user/lanwei94/solutions/solution05/wordcount
// hadoop fs -rm -R /user/lanwei94/solutions/solution05/wordcount

spark-shell --master yarn \
--conf spark.ui.port=12345 \
--num-executors 10 \
--executor-cores 2 \
--executor-memory 3G \
--packages com.databricks:spark-avro_2.10:2.0.1

import com.databricks.spark.avro._

val twitter = sc.textFile("/public/randomtextwriter")
val words = twitter.flatMap(rec => rec.split(" "))
val words_tuple = words.map(rec => (rec, 1))

//words_tuple.take(10).foreach(println)

val words_count = words_tuple.reduceByKey((x, y) => x+y, 8).toDF("word", "count")
//words_count.take(10).foreach(println)

words_count.write.avro("/user/lanwei94/solutions/solution05/wordcount")
// words_count.save("/user/lanwei94/solutions/solution05/wordcount", "avro")





